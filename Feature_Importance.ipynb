{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b5aaf08e-4fbf-4c70-8a56-dfbaafaecd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split \n",
    "import time\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "def rfe_feature_selection(indep_X, dep_Y, n_features):\n",
    "    from sklearn.feature_selection import RFE\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "    # Define the model\n",
    "    model = LogisticRegression(random_state=0,solver='liblinear')\n",
    "\n",
    "    # Create RFE selector with the specified model and number of features\n",
    "    selector = RFE(estimator=model, n_features_to_select=n_features)\n",
    "    selector.fit(indep_X, dep_Y)\n",
    "\n",
    "    # Transform the features to keep the selected ones\n",
    "    selected_features = selector.transform(indep_X)\n",
    "    return selected_features\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def split_scalar(indep_X, dep_Y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(indep_X, dep_Y, test_size=0.25, random_state=0)\n",
    "    sc = StandardScaler()\n",
    "    X_train = sc.fit_transform(X_train)\n",
    "    X_test = sc.transform(X_test)    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def cm_prediction(classifier, X_test, y_test):\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    \n",
    "    # Making the Confusion Matrix\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    from sklearn.metrics import accuracy_score \n",
    "    from sklearn.metrics import classification_report \n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    return classifier, accuracy, report, X_test, y_test, cm\n",
    "\n",
    "def logistic(X_train, y_train, X_test, y_test):       \n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    classifier = LogisticRegression(random_state=0)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    return cm_prediction(classifier, X_test, y_test)\n",
    "\n",
    "def svm_linear(X_train, y_train, X_test, y_test):\n",
    "    from sklearn.svm import SVC\n",
    "    classifier = SVC(kernel='linear', random_state=0)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    return cm_prediction(classifier, X_test, y_test)\n",
    "\n",
    "def svm_NL(X_train, y_train, X_test, y_test):\n",
    "    from sklearn.svm import SVC\n",
    "    classifier = SVC(kernel='rbf', random_state=0)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    return cm_prediction(classifier, X_test, y_test)\n",
    "\n",
    "def naive(X_train, y_train, X_test, y_test):       \n",
    "    from sklearn.naive_bayes import GaussianNB\n",
    "    classifier = GaussianNB()\n",
    "    classifier.fit(X_train, y_train)\n",
    "    return cm_prediction(classifier, X_test, y_test)\n",
    "\n",
    "def knn(X_train, y_train, X_test, y_test):\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    classifier = KNeighborsClassifier(n_neighbors=5, metric='minkowski', p=2)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    return cm_prediction(classifier, X_test, y_test)\n",
    "\n",
    "def decision(X_train, y_train, X_test, y_test):\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    classifier = DecisionTreeClassifier(criterion='entropy', random_state=0)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    return cm_prediction(classifier, X_test, y_test)\n",
    "\n",
    "def random(X_train, y_train, X_test, y_test):\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    classifier = RandomForestClassifier(n_estimators=10, criterion='entropy', random_state=0)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    return cm_prediction(classifier, X_test, y_test)\n",
    "\n",
    "def selectk_Classification(acclog, accsvml, accsvmnl, accknn, accnav, accdes, accrf): \n",
    "    dataframe = pd.DataFrame(index=['RFE'], columns=['Logistic', 'SVMl', 'SVMnl', 'KNN', 'Naive', 'Decision', 'Random'])\n",
    "    for number, idex in enumerate(dataframe.index):      \n",
    "        dataframe['Logistic'][idex] = acclog[number]       \n",
    "        dataframe['SVMl'][idex] = accsvml[number]\n",
    "        dataframe['SVMnl'][idex] = accsvmnl[number]\n",
    "        dataframe['KNN'][idex] = accknn[number]\n",
    "        dataframe['Naive'][idex] = accnav[number]\n",
    "        dataframe['Decision'][idex] = accdes[number]\n",
    "        dataframe['Random'][idex] = accrf[number]\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fa17b2fc-3552-48dd-9482-1304d20b8155",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1=pd.read_csv(\"Prep.csv\",index_col=None)\n",
    "\n",
    "df2=dataset1\n",
    "\n",
    "df2 = pd.get_dummies(df2, drop_first=True)\n",
    "\n",
    "indep_X=df2.drop('classification_yes',axis=1) \n",
    "dep_Y=df2['classification_yes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fa1c5d93-eedd-4a62-9111-314ae0508e50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['age', 'bp', 'al', 'su', 'bgr', 'bu', 'sc', 'sod', 'pot', 'hrmo', 'pcv',\n",
      "       'wc', 'rc', 'sg_b', 'sg_c', 'sg_d', 'sg_e', 'rbc_normal', 'pc_normal',\n",
      "       'pcc_present', 'ba_present', 'htn_yes', 'dm_yes', 'cad_yes',\n",
      "       'appet_yes', 'pe_yes', 'ane_yes', 'classification_yes'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df2.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e3b69974-217d-4273-a7ae-72ec1a5b31d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bp</th>\n",
       "      <th>al</th>\n",
       "      <th>su</th>\n",
       "      <th>bgr</th>\n",
       "      <th>bu</th>\n",
       "      <th>sc</th>\n",
       "      <th>sod</th>\n",
       "      <th>pot</th>\n",
       "      <th>hrmo</th>\n",
       "      <th>...</th>\n",
       "      <th>pc_normal</th>\n",
       "      <th>pcc_present</th>\n",
       "      <th>ba_present</th>\n",
       "      <th>htn_yes</th>\n",
       "      <th>dm_yes</th>\n",
       "      <th>cad_yes</th>\n",
       "      <th>appet_yes</th>\n",
       "      <th>pe_yes</th>\n",
       "      <th>ane_yes</th>\n",
       "      <th>classification_yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>76.459948</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>148.112676</td>\n",
       "      <td>57.482105</td>\n",
       "      <td>3.077356</td>\n",
       "      <td>137.528754</td>\n",
       "      <td>4.627244</td>\n",
       "      <td>12.518156</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>76.459948</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>148.112676</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>137.528754</td>\n",
       "      <td>4.627244</td>\n",
       "      <td>10.700000</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>76.459948</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>138.000000</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>76.459948</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>148.112676</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>138.000000</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>8.100000</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>148.112676</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>137.528754</td>\n",
       "      <td>4.627244</td>\n",
       "      <td>11.800000</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>51.492308</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>219.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>139.000000</td>\n",
       "      <td>3.700000</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>51.492308</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>220.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>137.528754</td>\n",
       "      <td>4.627244</td>\n",
       "      <td>8.700000</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>51.492308</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>115.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>2.700000</td>\n",
       "      <td>9.100000</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>51.492308</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>6.800000</td>\n",
       "      <td>142.000000</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>51.492308</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>16.300000</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>399 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           age         bp   al   su         bgr          bu        sc  \\\n",
       "0     2.000000  76.459948  3.0  0.0  148.112676   57.482105  3.077356   \n",
       "1     3.000000  76.459948  2.0  0.0  148.112676   22.000000  0.700000   \n",
       "2     4.000000  76.459948  1.0  0.0   99.000000   23.000000  0.600000   \n",
       "3     5.000000  76.459948  1.0  0.0  148.112676   16.000000  0.700000   \n",
       "4     5.000000  50.000000  0.0  0.0  148.112676   25.000000  0.600000   \n",
       "..         ...        ...  ...  ...         ...         ...       ...   \n",
       "394  51.492308  70.000000  0.0  0.0  219.000000   36.000000  1.300000   \n",
       "395  51.492308  70.000000  0.0  2.0  220.000000   68.000000  2.800000   \n",
       "396  51.492308  70.000000  3.0  0.0  110.000000  115.000000  6.000000   \n",
       "397  51.492308  90.000000  0.0  0.0  207.000000   80.000000  6.800000   \n",
       "398  51.492308  80.000000  0.0  0.0  100.000000   49.000000  1.000000   \n",
       "\n",
       "            sod       pot       hrmo  ...  pc_normal  pcc_present  ba_present  \\\n",
       "0    137.528754  4.627244  12.518156  ...      False        False       False   \n",
       "1    137.528754  4.627244  10.700000  ...       True        False       False   \n",
       "2    138.000000  4.400000  12.000000  ...       True        False       False   \n",
       "3    138.000000  3.200000   8.100000  ...       True        False       False   \n",
       "4    137.528754  4.627244  11.800000  ...       True        False       False   \n",
       "..          ...       ...        ...  ...        ...          ...         ...   \n",
       "394  139.000000  3.700000  12.500000  ...       True        False       False   \n",
       "395  137.528754  4.627244   8.700000  ...       True        False       False   \n",
       "396  134.000000  2.700000   9.100000  ...       True        False       False   \n",
       "397  142.000000  5.500000   8.500000  ...       True        False       False   \n",
       "398  140.000000  5.000000  16.300000  ...       True        False       False   \n",
       "\n",
       "     htn_yes  dm_yes  cad_yes  appet_yes  pe_yes  ane_yes  classification_yes  \n",
       "0      False   False    False       True    True    False                True  \n",
       "1      False   False    False       True   False    False                True  \n",
       "2      False   False    False       True   False    False                True  \n",
       "3      False   False    False       True   False     True                True  \n",
       "4      False   False    False       True   False    False                True  \n",
       "..       ...     ...      ...        ...     ...      ...                 ...  \n",
       "394    False   False    False       True   False    False                True  \n",
       "395     True    True    False       True   False     True                True  \n",
       "396     True    True    False      False   False    False                True  \n",
       "397     True    True    False       True   False     True                True  \n",
       "398    False   False    False       True   False    False               False  \n",
       "\n",
       "[399 rows x 28 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "881c0f4b-55d3-4711-b389-ca7d65ca442c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your dataset\n",
    "dataset1 = pd.read_csv(\"Prep.csv\", index_col=None)\n",
    "\n",
    "# Create a copy of the dataset\n",
    "df2 = dataset1.copy()\n",
    "\n",
    "# Convert categorical variables into dummy/indicator variables\n",
    "df2 = pd.get_dummies(df2, drop_first=True)\n",
    "\n",
    "# Separate the independent variables (X) and dependent variable (Y)\n",
    "indep_X = df2.drop('classification_yes', axis=1)\n",
    "dep_Y = df2['classification_yes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c6ed6c7d-4e40-4c56-bfbe-53636a40df9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfe_selected_features = rfe_feature_selection(indep_X, dep_Y, 2)    \n",
    "\n",
    "acclog=[]\n",
    "accsvml=[]\n",
    "accsvmnl=[]\n",
    "accknn=[]\n",
    "accnav=[]\n",
    "accdes=[]\n",
    "accrf=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a06e5584-2e59-4f59-b28b-58534a0fdb05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 0.],\n",
       "       [1., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [1., 1.],\n",
       "       [0., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [1., 1.],\n",
       "       [0., 0.],\n",
       "       [1., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [1., 1.],\n",
       "       [0., 0.],\n",
       "       [1., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [1., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 0.],\n",
       "       [1., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [1., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 1.],\n",
       "       [0., 0.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [0., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [1., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [1., 1.],\n",
       "       [0., 0.],\n",
       "       [1., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 1.],\n",
       "       [0., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [1., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [1., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [1., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 0.]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfe_selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "879a5c6f-df5a-40e6-a77f-12afdaed7ad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sindhiya maria\\AppData\\Local\\Temp\\ipykernel_8148\\1258135336.py:97: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  dataframe['Logistic'][idex] = acclog[number]\n",
      "C:\\Users\\sindhiya maria\\AppData\\Local\\Temp\\ipykernel_8148\\1258135336.py:98: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  dataframe['SVMl'][idex] = accsvml[number]\n",
      "C:\\Users\\sindhiya maria\\AppData\\Local\\Temp\\ipykernel_8148\\1258135336.py:99: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  dataframe['SVMnl'][idex] = accsvmnl[number]\n",
      "C:\\Users\\sindhiya maria\\AppData\\Local\\Temp\\ipykernel_8148\\1258135336.py:100: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  dataframe['KNN'][idex] = accknn[number]\n",
      "C:\\Users\\sindhiya maria\\AppData\\Local\\Temp\\ipykernel_8148\\1258135336.py:101: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  dataframe['Naive'][idex] = accnav[number]\n",
      "C:\\Users\\sindhiya maria\\AppData\\Local\\Temp\\ipykernel_8148\\1258135336.py:102: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  dataframe['Decision'][idex] = accdes[number]\n",
      "C:\\Users\\sindhiya maria\\AppData\\Local\\Temp\\ipykernel_8148\\1258135336.py:103: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  dataframe['Random'][idex] = accrf[number]\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test=split_scalar(rfe_selected_features,dep_Y)   \n",
    "\n",
    "classifier, Accuracy, report, X_test, y_test, cm = logistic(X_train, y_train, X_test, y_test)\n",
    "acclog.append(Accuracy)\n",
    "\n",
    "classifier, Accuracy, report, X_test, y_test, cm = svm_linear(X_train, y_train, X_test, y_test)  \n",
    "accsvml.append(Accuracy)\n",
    "\n",
    "classifier, Accuracy, report, X_test, y_test, cm = svm_NL(X_train, y_train, X_test, y_test)  \n",
    "accsvmnl.append(Accuracy)\n",
    "\n",
    "classifier, Accuracy, report, X_test, y_test, cm = knn(X_train, y_train, X_test, y_test)  \n",
    "accknn.append(Accuracy)\n",
    "\n",
    "classifier, Accuracy, report, X_test, y_test, cm = naive(X_train, y_train, X_test, y_test)  \n",
    "accnav.append(Accuracy)\n",
    "\n",
    "classifier, Accuracy, report, X_test, y_test, cm = decision(X_train, y_train, X_test, y_test)  \n",
    "accdes.append(Accuracy)\n",
    "\n",
    "classifier, Accuracy, report, X_test, y_test, cm = random(X_train, y_train, X_test, y_test)  \n",
    "accrf.append(Accuracy)\n",
    "\n",
    "result = selectk_Classification(acclog, accsvml, accsvmnl, accknn, accnav, accdes, accrf)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22ae24ac-133b-4d71-ad99-031188105d2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Logistic</th>\n",
       "      <th>SVMl</th>\n",
       "      <th>SVMnl</th>\n",
       "      <th>KNN</th>\n",
       "      <th>Naive</th>\n",
       "      <th>Decision</th>\n",
       "      <th>Random</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RFE</th>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Logistic  SVMl SVMnl   KNN Naive Decision Random\n",
       "RFE     0.98  0.98  0.98  0.98  0.98     0.98   0.98"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result #5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1f9dd3f8-271b-4cc4-a317-30d16743b0b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Logistic</th>\n",
       "      <th>SVMl</th>\n",
       "      <th>SVMnl</th>\n",
       "      <th>KNN</th>\n",
       "      <th>Naive</th>\n",
       "      <th>Decision</th>\n",
       "      <th>Random</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RFE</th>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Logistic  SVMl SVMnl   KNN Naive Decision Random\n",
       "RFE     0.98  0.98  0.98  0.96  0.98     0.98   0.98"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result #6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c25fcd86-106f-4525-9d5c-3a5cd9db99cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Logistic</th>\n",
       "      <th>SVMl</th>\n",
       "      <th>SVMnl</th>\n",
       "      <th>KNN</th>\n",
       "      <th>Naive</th>\n",
       "      <th>Decision</th>\n",
       "      <th>Random</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RFE</th>\n",
       "      <td>0.94</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Logistic  SVMl SVMnl   KNN Naive Decision Random\n",
       "RFE     0.94  0.94  0.94  0.94  0.94     0.94   0.94"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result #3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7a67925d-a5ea-4170-9c0c-6a243ed749c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Logistic</th>\n",
       "      <th>SVMl</th>\n",
       "      <th>SVMnl</th>\n",
       "      <th>KNN</th>\n",
       "      <th>Naive</th>\n",
       "      <th>Decision</th>\n",
       "      <th>Random</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RFE</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Logistic  SVMl SVMnl   KNN Naive Decision Random\n",
       "RFE     0.95  0.95  0.95  0.95  0.95     0.95   0.95"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result #4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d334a751-fc75-4def-ab2c-a51266959399",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Logistic</th>\n",
       "      <th>SVMl</th>\n",
       "      <th>SVMnl</th>\n",
       "      <th>KNN</th>\n",
       "      <th>Naive</th>\n",
       "      <th>Decision</th>\n",
       "      <th>Random</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RFE</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Logistic  SVMl SVMnl   KNN Naive Decision Random\n",
       "RFE     0.84  0.84  0.84  0.84  0.84     0.84   0.84"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e10643-5f9c-430b-8506-6951d515a9f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
